Using device: cuda
Conformer(
  (encoder): ConformerEncoder(
    (conv_subsample): Conv2dSubampling(
      (sequential): Sequential(
        (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
    )
    (input_projection): Sequential(
      (0): Linear(
        (linear): Linear(in_features=2432, out_features=128, bias=True)
      )
      (1): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0): ConformerBlock(
        (sequential): Sequential(
          (0): ResidualConnectionModule(
            (module): FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(
                  (linear): Linear(in_features=128, out_features=512, bias=True)
                )
                (2): Swish()
                (3): Dropout(p=0.1, inplace=False)
                (4): Linear(
                  (linear): Linear(in_features=512, out_features=128, bias=True)
                )
                (5): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (1): ResidualConnectionModule(
            (module): MultiHeadedSelfAttentionModule(
              (positional_encoding): RelPositionalEncoding()
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attention): RelativeMultiHeadAttention(
                (query_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (key_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (value_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (pos_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=False)
                )
                (dropout): Dropout(p=0.1, inplace=False)
                (out_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
              )
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): ResidualConnectionModule(
            (module): ConformerConvModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Transpose()
                (2): PointwiseConv1d(
                  (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
                )
                (3): GLU()
                (4): DepthwiseConv1d(
                  (conv): Conv1d(128, 128, kernel_size=(31,), stride=(1,), padding=(15,), groups=128, bias=False)
                )
                (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (6): Swish()
                (7): PointwiseConv1d(
                  (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (8): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (3): ResidualConnectionModule(
            (module): FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(
                  (linear): Linear(in_features=128, out_features=512, bias=True)
                )
                (2): Swish()
                (3): Dropout(p=0.1, inplace=False)
                (4): Linear(
                  (linear): Linear(in_features=512, out_features=128, bias=True)
                )
                (5): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): ConformerBlock(
        (sequential): Sequential(
          (0): ResidualConnectionModule(
            (module): FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(
                  (linear): Linear(in_features=128, out_features=512, bias=True)
                )
                (2): Swish()
                (3): Dropout(p=0.1, inplace=False)
                (4): Linear(
                  (linear): Linear(in_features=512, out_features=128, bias=True)
                )
                (5): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (1): ResidualConnectionModule(
            (module): MultiHeadedSelfAttentionModule(
              (positional_encoding): RelPositionalEncoding()
              (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (attention): RelativeMultiHeadAttention(
                (query_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (key_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (value_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
                (pos_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=False)
                )
                (dropout): Dropout(p=0.1, inplace=False)
                (out_proj): Linear(
                  (linear): Linear(in_features=128, out_features=128, bias=True)
                )
              )
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): ResidualConnectionModule(
            (module): ConformerConvModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Transpose()
                (2): PointwiseConv1d(
                  (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
                )
                (3): GLU()
                (4): DepthwiseConv1d(
                  (conv): Conv1d(128, 128, kernel_size=(31,), stride=(1,), padding=(15,), groups=128, bias=False)
                )
                (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (6): Swish()
                (7): PointwiseConv1d(
                  (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (8): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (3): ResidualConnectionModule(
            (module): FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (1): Linear(
                  (linear): Linear(in_features=128, out_features=512, bias=True)
                )
                (2): Swish()
                (3): Dropout(p=0.1, inplace=False)
                (4): Linear(
                  (linear): Linear(in_features=512, out_features=128, bias=True)
                )
                (5): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (fc): Linear(
    (linear): Linear(in_features=128, out_features=35, bias=False)
  )
)
[Info] 初始模型權重已從 ./checkpoints/h0.pt 加載。
[Info] 保存檢查點到 ./checkpoints/20250105_195031

Epoch 1/5
Step 0, Loss: 1.9448
Step 10, Loss: 1.8525
Step 20, Loss: 1.8811
Step 30, Loss: 1.8917
Step 40, Loss: 1.8645
Step 50, Loss: 1.8056
Step 60, Loss: 1.8006
Step 70, Loss: 1.8807
Step 80, Loss: 1.8187
Step 90, Loss: 1.8536
Step 100, Loss: 1.8004
Step 110, Loss: 1.8629
Step 120, Loss: 1.8524
Step 130, Loss: 1.7387
Step 140, Loss: 1.8153
Step 150, Loss: 1.8597
Step 160, Loss: 1.7462
Step 170, Loss: 1.7747
Step 180, Loss: 1.7816
Step 190, Loss: 1.7384
Step 200, Loss: 1.7131
Step 210, Loss: 1.7154
Step 220, Loss: 1.7399
Step 230, Loss: 1.8568
Step 240, Loss: 1.9123
Step 250, Loss: 1.7860
Step 260, Loss: 1.7123
Step 270, Loss: 1.6942
Step 280, Loss: 1.8215
Step 290, Loss: 1.7968
Step 300, Loss: 1.7213
Step 310, Loss: 1.7430
Step 320, Loss: 1.8089
Step 330, Loss: 1.7760
Step 340, Loss: 1.8718
Step 350, Loss: 1.8523
Step 360, Loss: 1.6450
Step 370, Loss: 1.7189
Step 380, Loss: 1.6681
Step 390, Loss: 1.7203
Step 400, Loss: 1.7172
Step 410, Loss: 1.7540
Step 420, Loss: 1.7116
Step 430, Loss: 1.7708
Step 440, Loss: 1.6745
Step 450, Loss: 1.7393
Step 460, Loss: 1.7379
Step 470, Loss: 1.6787
Step 480, Loss: 1.6304
Step 490, Loss: 1.6894
Step 500, Loss: 1.6810
Step 510, Loss: 1.7087
Step 520, Loss: 1.7417
Step 530, Loss: 1.7992
Step 540, Loss: 1.7374
Step 550, Loss: 1.8636
Step 560, Loss: 1.6758
Step 570, Loss: 1.8089
Step 580, Loss: 1.7519
Step 590, Loss: 1.7221
Step 600, Loss: 1.7375
Step 610, Loss: 1.6168
Step 620, Loss: 1.7826
Step 630, Loss: 1.6924
Step 640, Loss: 1.6478
Step 650, Loss: 1.7844
Step 660, Loss: 1.7629
Step 670, Loss: 1.8343
Step 680, Loss: 1.6513
Step 690, Loss: 1.8047
Step 700, Loss: 1.6795
Step 710, Loss: 1.7495
Step 720, Loss: 1.8650
Step 730, Loss: 1.7805
Step 740, Loss: 1.7243
Step 750, Loss: 1.8275
Step 760, Loss: 1.6931
Step 770, Loss: 1.8399
Step 780, Loss: 1.6355
Step 790, Loss: 1.8207
Step 800, Loss: 1.7249
Step 810, Loss: 1.5831
Step 820, Loss: 1.6142
Step 830, Loss: 1.7108
Step 840, Loss: 1.6690
Step 850, Loss: 1.6728
Step 860, Loss: 1.7867
Step 870, Loss: 1.7406
Step 880, Loss: 1.7057
Step 890, Loss: 1.7864
Step 900, Loss: 1.7387
Step 910, Loss: 1.6750
Step 920, Loss: 1.7580
Step 930, Loss: 1.7119
Step 940, Loss: 1.7423
Step 950, Loss: 1.6674
Step 960, Loss: 1.7189
Step 970, Loss: 1.7176
Step 980, Loss: 1.6674
Step 990, Loss: 1.6460
Epoch 1, Average Loss: 1.7593
[Info] 模型檢查點已保存至 ./checkpoints/20250105_195031/epoch_1.pt

Epoch 2/5
Step 0, Loss: 1.6057
Step 10, Loss: 1.5693
Step 20, Loss: 1.7624
Step 30, Loss: 1.6640
Step 40, Loss: 1.6712
Step 50, Loss: 1.7324
Step 60, Loss: 1.7380
Step 70, Loss: 1.6628
Step 80, Loss: 1.6315
Step 90, Loss: 1.8137
Step 100, Loss: 1.8215
Step 110, Loss: 1.6719
Step 120, Loss: 1.6431
Step 130, Loss: 1.7365
Step 140, Loss: 1.7743
Step 150, Loss: 1.6746
Step 160, Loss: 1.6874
Step 170, Loss: 1.6451
Step 180, Loss: 1.6977
Step 190, Loss: 1.7346
Step 200, Loss: 1.6584
Step 210, Loss: 1.6443
Step 220, Loss: 1.7407
Step 230, Loss: 1.7826
Step 240, Loss: 1.8258
Step 250, Loss: 1.5689
Step 260, Loss: 1.6231
Step 270, Loss: 1.6327
Step 280, Loss: 1.7053
Step 290, Loss: 1.7971
Step 300, Loss: 1.7039
Step 310, Loss: 1.7385
Step 320, Loss: 1.7390
Step 330, Loss: 1.7174
Step 340, Loss: 1.6993
Step 350, Loss: 1.6516
Step 360, Loss: 1.6497
Step 370, Loss: 1.6299
Step 380, Loss: 1.5912
Step 390, Loss: 1.7633
Step 400, Loss: 1.7662
Step 410, Loss: 1.6103
Step 420, Loss: 1.7662
Step 430, Loss: 1.7129
Step 440, Loss: 1.7177
Step 450, Loss: 1.7475
Step 460, Loss: 1.7002
Step 470, Loss: 1.7275
Step 480, Loss: 1.6551
Step 490, Loss: 1.7396
Step 500, Loss: 1.6866
Step 510, Loss: 1.6140
Step 520, Loss: 1.7227
Step 530, Loss: 1.8395
Step 540, Loss: 1.7018
Step 550, Loss: 1.8342
Step 560, Loss: 1.6108
Step 570, Loss: 1.7681
Step 580, Loss: 1.5998
Step 590, Loss: 1.6843
Step 600, Loss: 1.8192
Step 610, Loss: 1.6980
Step 620, Loss: 1.7182
Step 630, Loss: 1.6292
Step 640, Loss: 1.5279
Step 650, Loss: 1.7352
Step 660, Loss: 1.5778
Step 670, Loss: 1.7156
Step 680, Loss: 1.7249
Step 690, Loss: 1.7308
Step 700, Loss: 1.6689
Step 710, Loss: 1.6408
Step 720, Loss: 1.7419
Step 730, Loss: 1.6004
Step 740, Loss: 1.6177
Step 750, Loss: 1.7160
Step 760, Loss: 1.6765
Step 770, Loss: 1.6677
Step 780, Loss: 1.5856
Step 790, Loss: 1.5762
Step 800, Loss: 1.7078
Step 810, Loss: 1.6263
Step 820, Loss: 1.5754
Step 830, Loss: 1.6694
Step 840, Loss: 1.6119
Step 850, Loss: 1.6020
Step 860, Loss: 1.6752
Step 870, Loss: 1.6643
Step 880, Loss: 1.6578
Step 890, Loss: 1.7535
Step 900, Loss: 1.6739
Step 910, Loss: 1.6890
Step 920, Loss: 1.7546
Step 930, Loss: 1.6382
Step 940, Loss: 1.6966
Step 950, Loss: 1.6322
Step 960, Loss: 1.6527
Step 970, Loss: 1.6838
Step 980, Loss: 1.6773
Step 990, Loss: 1.6729
Epoch 2, Average Loss: 1.6894
[Info] 模型檢查點已保存至 ./checkpoints/20250105_195031/epoch_2.pt

Epoch 3/5
Step 0, Loss: 1.6802
Step 10, Loss: 1.5823
Step 20, Loss: 1.7513
Step 30, Loss: 1.7190
Step 40, Loss: 1.6362
Step 50, Loss: 1.7272
Step 60, Loss: 1.7409
Step 70, Loss: 1.6990
Step 80, Loss: 1.6531
Step 90, Loss: 1.7850
Step 100, Loss: 1.7759
Step 110, Loss: 1.7016
Step 120, Loss: 1.7148
Step 130, Loss: 1.7176
Step 140, Loss: 1.7120
Step 150, Loss: 1.6978
Step 160, Loss: 1.7425
Step 170, Loss: 1.6796
Step 180, Loss: 1.6695
Step 190, Loss: 1.7063
Step 200, Loss: 1.6616
Step 210, Loss: 1.6205
Step 220, Loss: 1.6916
Step 230, Loss: 1.7831
Step 240, Loss: 1.7380
Step 250, Loss: 1.6207
Step 260, Loss: 1.6497
Step 270, Loss: 1.6645
Step 280, Loss: 1.6721
Step 290, Loss: 1.7878
Step 300, Loss: 1.6869
Step 310, Loss: 1.8079
Step 320, Loss: 1.6927
Step 330, Loss: 1.6506
Step 340, Loss: 1.6533
Step 350, Loss: 1.5990
Step 360, Loss: 1.6224
Step 370, Loss: 1.5854
Step 380, Loss: 1.6247
Step 390, Loss: 1.6734
Step 400, Loss: 1.7531
Step 410, Loss: 1.7441
Step 420, Loss: 1.7444
Step 430, Loss: 1.6160
Step 440, Loss: 1.6529
Step 450, Loss: 1.7517
Step 460, Loss: 1.7852
Step 470, Loss: 1.6978
Step 480, Loss: 1.7196
Step 490, Loss: 1.7046
Step 500, Loss: 1.6758
Step 510, Loss: 1.6420
Step 520, Loss: 1.7164
Step 530, Loss: 1.7155
Step 540, Loss: 1.7859
Step 550, Loss: 1.7755
Step 560, Loss: 1.5727
Step 570, Loss: 1.6872
Step 580, Loss: 1.6157
Step 590, Loss: 1.6184
Step 600, Loss: 1.7850
Step 610, Loss: 1.6316
Step 620, Loss: 1.7251
Step 630, Loss: 1.5868
Step 640, Loss: 1.5610
Step 650, Loss: 1.6930
Step 660, Loss: 1.5977
Step 670, Loss: 1.6652
Step 680, Loss: 1.6532
Step 690, Loss: 1.7952
Step 700, Loss: 1.6402
Step 710, Loss: 1.7160
Step 720, Loss: 1.7867
Step 730, Loss: 1.5884
Step 740, Loss: 1.6368
Step 750, Loss: 1.7648
Step 760, Loss: 1.6917
Step 770, Loss: 1.7084
Step 780, Loss: 1.5282
Step 790, Loss: 1.5959
Step 800, Loss: 1.6927
Step 810, Loss: 1.5573
Step 820, Loss: 1.5611
Step 830, Loss: 1.6468
Step 840, Loss: 1.6303
Step 850, Loss: 1.6243
Step 860, Loss: 1.6474
Step 870, Loss: 1.6456
Step 880, Loss: 1.6752
Step 890, Loss: 1.7093
Step 900, Loss: 1.6484
Step 910, Loss: 1.7255
Step 920, Loss: 1.6795
Step 930, Loss: 1.6082
Step 940, Loss: 1.6736
Step 950, Loss: 1.6186
Step 960, Loss: 1.6392
Step 970, Loss: 1.6513
Step 980, Loss: 1.6325
Step 990, Loss: 1.6080
Epoch 3, Average Loss: 1.6741
[Info] 模型檢查點已保存至 ./checkpoints/20250105_195031/epoch_3.pt

Epoch 4/5
Step 0, Loss: 1.6384
Step 10, Loss: 1.5636
Step 20, Loss: 1.7349
Step 30, Loss: 1.6578
Step 40, Loss: 1.6520
Step 50, Loss: 1.7213
Step 60, Loss: 1.6919
Step 70, Loss: 1.5979
Step 80, Loss: 1.6389
Step 90, Loss: 1.7940
Step 100, Loss: 1.7331
Step 110, Loss: 1.7158
Step 120, Loss: 1.7689
Step 130, Loss: 1.7147
Step 140, Loss: 1.7115
Step 150, Loss: 1.6822
Step 160, Loss: 1.7208
Step 170, Loss: 1.6934
Step 180, Loss: 1.6110
Step 190, Loss: 1.6690
Step 200, Loss: 1.6330
Step 210, Loss: 1.6164
Step 220, Loss: 1.6488
Step 230, Loss: 1.6846
Step 240, Loss: 1.7646
Step 250, Loss: 1.5633
Step 260, Loss: 1.6129
Step 270, Loss: 1.6890
Step 280, Loss: 1.6350
Step 290, Loss: 1.7251
Step 300, Loss: 1.6454
Step 310, Loss: 1.7350
Step 320, Loss: 1.7531
Step 330, Loss: 1.6693
Step 340, Loss: 1.6583
Step 350, Loss: 1.5753
Step 360, Loss: 1.6143
Step 370, Loss: 1.6465
Step 380, Loss: 1.6002
Step 390, Loss: 1.6493
Step 400, Loss: 1.6934
Step 410, Loss: 1.5852
Step 420, Loss: 1.7254
Step 430, Loss: 1.5795
Step 440, Loss: 1.6965
Step 450, Loss: 1.6998
Step 460, Loss: 1.6913
Step 470, Loss: 1.7400
Step 480, Loss: 1.6221
Step 490, Loss: 1.6915
Step 500, Loss: 1.6625
Step 510, Loss: 1.6930
Step 520, Loss: 1.7088
Step 530, Loss: 1.7241
Step 540, Loss: 1.6812
Step 550, Loss: 1.8319
Step 560, Loss: 1.5659
Step 570, Loss: 1.7224
Step 580, Loss: 1.5755
Step 590, Loss: 1.6294
Step 600, Loss: 1.8061
Step 610, Loss: 1.6640
Step 620, Loss: 1.7462
Step 630, Loss: 1.6411
Step 640, Loss: 1.5775
Step 650, Loss: 1.7081
Step 660, Loss: 1.6534
Step 670, Loss: 1.6599
Step 680, Loss: 1.6696
Step 690, Loss: 1.7459
Step 700, Loss: 1.6891
Step 710, Loss: 1.5984
Step 720, Loss: 1.7399
Step 730, Loss: 1.5594
Step 740, Loss: 1.5797
Step 750, Loss: 1.6568
Step 760, Loss: 1.7159
Step 770, Loss: 1.6240
Step 780, Loss: 1.5086
Step 790, Loss: 1.5823
Step 800, Loss: 1.6775
Step 810, Loss: 1.5617
Step 820, Loss: 1.6149
Step 830, Loss: 1.6781
Step 840, Loss: 1.6090
Step 850, Loss: 1.6337
Step 860, Loss: 1.6381
Step 870, Loss: 1.7498
Step 880, Loss: 1.6128
Step 890, Loss: 1.6978
Step 900, Loss: 1.6804
Step 910, Loss: 1.6734
Step 920, Loss: 1.7023
Step 930, Loss: 1.6109
Step 940, Loss: 1.6408
Step 950, Loss: 1.6132
Step 960, Loss: 1.6351
Step 970, Loss: 1.6467
Step 980, Loss: 1.6555
Step 990, Loss: 1.6164
Epoch 4, Average Loss: 1.6671
[Info] 模型檢查點已保存至 ./checkpoints/20250105_195031/epoch_4.pt

Epoch 5/5
Step 0, Loss: 1.6457
Step 10, Loss: 1.5574
Step 20, Loss: 1.7443
Step 30, Loss: 1.6542
Step 40, Loss: 1.6371
Step 50, Loss: 1.7303
Step 60, Loss: 1.7342
Step 70, Loss: 1.6817
Step 80, Loss: 1.5573
Step 90, Loss: 1.7354
Step 100, Loss: 1.7205
Step 110, Loss: 1.6588
Step 120, Loss: 1.6484
Step 130, Loss: 1.6999
Step 140, Loss: 1.6608
Step 150, Loss: 1.7134
Step 160, Loss: 1.6836
Step 170, Loss: 1.6616
Step 180, Loss: 1.6432
Step 190, Loss: 1.6594
Step 200, Loss: 1.6367
Step 210, Loss: 1.6977
Step 220, Loss: 1.6856
Step 230, Loss: 1.7223
Step 240, Loss: 1.7342
Step 250, Loss: 1.5760
Step 260, Loss: 1.6315
Step 270, Loss: 1.6508
Step 280, Loss: 1.6527
Step 290, Loss: 1.6999
Step 300, Loss: 1.7137
Step 310, Loss: 1.7668
Step 320, Loss: 1.6700
Step 330, Loss: 1.7012
Step 340, Loss: 1.6467
Step 350, Loss: 1.5824
Step 360, Loss: 1.6744
Step 370, Loss: 1.5949
Step 380, Loss: 1.5961
Step 390, Loss: 1.6555
Step 400, Loss: 1.8103
Step 410, Loss: 1.7238
Step 420, Loss: 1.6993
Step 430, Loss: 1.5865
Step 440, Loss: 1.7156
Step 450, Loss: 1.6793
Step 460, Loss: 1.6766
Step 470, Loss: 1.7641
Step 480, Loss: 1.6380
Step 490, Loss: 1.6816
Step 500, Loss: 1.7124
Step 510, Loss: 1.6771
Step 520, Loss: 1.6901
Step 530, Loss: 1.7603
Step 540, Loss: 1.6493
Step 550, Loss: 1.7855
Step 560, Loss: 1.5937
Step 570, Loss: 1.7039
Step 580, Loss: 1.5791
Step 590, Loss: 1.6177
Step 600, Loss: 1.7807
Step 610, Loss: 1.6092
Step 620, Loss: 1.6846
Step 630, Loss: 1.5786
Step 640, Loss: 1.5673
Step 650, Loss: 1.6600
Step 660, Loss: 1.5942
Step 670, Loss: 1.6496
Step 680, Loss: 1.6377
Step 690, Loss: 1.8111
Step 700, Loss: 1.6524
Step 710, Loss: 1.5947
Step 720, Loss: 1.6838
Step 730, Loss: 1.5738
Step 740, Loss: 1.6124
Step 750, Loss: 1.6185
Step 760, Loss: 1.7063
Step 770, Loss: 1.6286
Step 780, Loss: 1.5360
Step 790, Loss: 1.6805
Step 800, Loss: 1.6607
Step 810, Loss: 1.5364
Step 820, Loss: 1.5770
Step 830, Loss: 1.6212
Step 840, Loss: 1.5824
Step 850, Loss: 1.5952
Step 860, Loss: 1.6397
Step 870, Loss: 1.7032
Step 880, Loss: 1.5994
Step 890, Loss: 1.6979
Step 900, Loss: 1.7067
Step 910, Loss: 1.6909
Step 920, Loss: 1.6828
Step 930, Loss: 1.6150
Step 940, Loss: 1.6673
Step 950, Loss: 1.5785
Step 960, Loss: 1.6733
Step 970, Loss: 1.6587
Step 980, Loss: 1.6253
Step 990, Loss: 1.5864
Epoch 5, Average Loss: 1.6625
[Info] 模型檢查點已保存至 ./checkpoints/20250105_195031/epoch_5.pt
